AI SOLUTION:
The solution is relevant to the theme because the area of Welkom experience earthquakes the most. Therefore, we have developed an AI model which will aim to predict the occurrence of future earthquakes by analyzing historical datasets, weather patterns and environmental conditions. The Earthquake predictor will be the best solution as it will give authorities and communities critical time to implement evacuation plans, secure infrastructure and initiative emergency measures.

OBJECTIVE OF THE BUSINESS: 
The main business goal of deploying AI Earthquake Predictor in Welkom is to Enhance the 
effectiveness, responsiveness, and efficiency of earthquake preparedness, response, and recovery 
efforts. To decrease the loss of lives, property, and resources in Welkom, utilizing AI technology 
is needed to better predict, monitor, and mitigate the impact of earthquake disaster. 
 
CRITERIA FOR BUSINESS SUCCESS: 
1. Accuracy and Reliability: AI Earthquake Predictor should offer precise and trustworthy 
forecasts and insights to support decision-making during earthquake disaster occurrences. 
2. Speed and Responsiveness: The Earthquake Predictor should be quick to react to changing 
circumstances and new dangers in order to make timely interventions. 
3. Facilitating Stakeholder Collaboration: The Earthquake Predictor should promote interaction 
and cooperation with stakeholders of the Welkom community.
4. Lessened Impact: The use of AI Earthquake Predictor should lessen the number of people 
killed, the amount of property damaged, and the overall impact of disasters. 
5. Long-term Planning: By evaluating past data and spotting trends, AI Earthquake Predictor can 
be utilized for long-term planning, improving calamity preparedness plans.

BUSINESS BACKGROUND: 
The purpose of us creating this AI Earthquake Predictor is to address the rising frequency and 
severity of earthquake disasters in Welkom. The complexity and size of modern Earthquake 
disasters are frequently beyond the capabilities of traditional disaster management techniques. 
Through the use of data-driven insights, predictive modeling, and real-time decision assistance, 
AI Earthquake Predictor has the ability to completely transform these procedures.

REQUIREMENTS, CONSTRAINTS, AND RISKS:
-REQUIREMENTS: The Earthquake predictor must be able to process and analyze large amounts of data from a variety of sources, such as sensor networks, data sets and historical records. It must deliver precise forecasts, useful insights, and assistance with decision-making. User interfaces should be simple to use and open to users of all technological backgrounds. 
- CONSTRAINTS: In disaster-stricken areas, the effectiveness of Earthquake predictor may be constrained by a lack of compute resources and network access. Data usage and sharing ethical issues must also be addressed, as do privacy problems. 
 - RISKS: Making judgments purely based on Earthquake predictor without human supervision may result in errors. Incorrect predictions could result from skewed training data. A focus on technology too much can overshadow the value of community involvement and local knowledge.

TOOLS AND TECHNIQUES:
- Machine learning: Creating predictive models for disaster occurrence, severity, and effect using historical data. 
- Natural Language Processing (NLP): Examining news reports and social media to find upcoming catastrophic occurrences and gauge public opinion. 
- Image analysis: analyzing imagery from satellites and drones to evaluate the damage and organize the best course of action. 
- Geographical Information Systems (GIS): Using spatial data integration, GIS can be used to efficiently allocate resources, plan evacuation routes, and show the effects of disasters. 
- Predictive Analytics: Using current data and past trends, disaster scenarios are forecast. 
- Collaboration platforms: Creating platforms for coordination and communication between stakeholders so they may exchange news and updates. 
Last but not least, using Earthquake predictor into disaster management is consistent with the objective of reducing the effects of disasters and saving lives. The success of such a project depends on precise forecasts, prompt reactions, and efficient cooperation amongst many parties. To ensure the appropriate and effective application of Earthquake predictor in this crucial domain, rigorous analysis of requirements, restrictions, and potential hazards is required.

PROBLEM DEFINITION

People of Welkom  are most likely to experience earthquake disaster  and this happen time to time. Community is always unaware when to expect this abnormal intensity of natural agent. What is worse is that they don’t even know how much damage will agent cause and how will they prepare themselves to survive all this trauma,so they are in need of AI solution that will help them to predict when to expect this situation. 

This problem is relevant to the theme because our community is suffering against damages, loss of lives, emotional and mental disturbance and for them to overcome this AI solution must be implemented. Therefore we have developed AI earthquake predictor.

Solving this matter will be beneficial to our community because:

1 loss of lives will be reduced
2 We will have low damage of infrastructure
3 low economic disruption
4 loss of food will be reduced
5 authorities will be prepared to act

MACHINE LEARNING APPROACH
 Our model will be trained to predict earthquake occurrence.
We’re going to utilize a supervised machine learning technique because will be using a collection of labelled data. The dataset contains information such as time of the day, longitude and magnitude. With this dataset, the relief organizations will be depending on data that has been gathered and shared through SMSes, http requests and satellite imagery to strengthen early warning techniques.  
  
DATA
The data will be organized or formulated so that it can be fed to the AI algorithms. After deciding on our machine learning strategy, we will proceed to pre-process the data so that it may be fed into the AI system. Data is initially presented in raw form, and in order for our model to understand it, it must first be transformed into useful data. This process is called pre-processing of data. We use three processes to handle data when developing AI in python. Step 1: Sci-kit learn will be used to normalize our data by comparing prior data with current data of our stats and specific patterns, and importing helpful packages and Numpy will be used to facilitate our mathematical operations like: how many TIMES will EARTHQUAKE occur each season in a year? 
We chose Welkom course is the one impacted by high level of earthquake, so it will be 
Primary target of management disaster, Step 2: Will define sample data. Step 3: Using various pre-processing approaches, we will apply binarization in our artificial intelligence system and end up using encoding where data requires to be converted from words to numerical values.

MODEL
Our model inspires the linear regression to model the relationship between earthquake magnitude and depth or location.
Earthquake prediction model is generated using Support Vector Regression (SVR) combine with Hybrid Neural Networks (HNN).
Applying the provided prediction method, earthquake predictions are carried out independently for the indicated areas, and the outcomes are evaluated.
Machine Learning (ML) can predict the geographic scope of an event by examining both previously generated and newly available data and is capable of creating models that forecast the length and severity of the earthquake event.

TIME SERIES ANALYSIS ON DATA
-Time series analysis will be used to predict the sequence of data.Machine Learning(ML) can help to improve the accuracy of time series forecasting by using libraries such as:
1 Pandas- we will use it for data manipulation and analysis.It will provide data structures like DataFrames and use it to load and preprocess dataset.
2 Twilio- Will alert us via SMSes about the potential risks or impact,  and predict future occurrences  of earthquake in the area of Welkom.

SOLUTION TECHNIQUE:
Techniques that our model is using to improve its accuracy are image analysis, GIS, collaboration platform, machine learning, and predictive analytics by scanning through social media 
posts and news to find topics about earthquake occurrence.
This will solve the problem of communities facing unexpected earthquake incidents since they will get warning to evacuate to safer places in time.

NATURAL LANGUAGE PROCESSING:
Human language is difficult for computer programs to understand, so we used natural language processing and its components, NLU and NLG to break down human text and voice data (inputs) 
to make sense of it in a way a computer can understand, with NLG producing meaningful phrases and sentences in the form of natural language from some internal representation such as 
sentence planning/lexical choice by using appropriate words that convey the meaning.
Our earthquake predictor model will use English because it is the most understandable language. We trained the algorithm to detect, in real-time, whether it's noise or an earthquake by 
analyzing patterns in seismic activity, geological data, and other factors to identify the probability of an earthquake occurring.

Deep Learning   
     
CNNs are commonly used for image analysis, including seismic image analysis. They will be applied to seismic data to identify patterns, fault lines, and geological features that might be indicative of potential earthquake activity.  
Long Short-Term Memory(LSTM) networks or Convolutional Neural Networks(CNNs) will be used to analyse historical meteorological data, oceanic conditions, and atmospheric  patterns   
Graph Neural Networks (GNNs): GNNs will used to analyze data structured as graphs, which can represent interconnected seismic sensors or fault networks. GNNs will enable the modeling of relationships between different elements in the data, aiding in earthquake risk assessment.  
   
Multi-layer perception  
   
We will use it in different stages such as prediction classification, and decisionmaking.   
It will be used to classify the type of disaster based on the input data such as satellite images, weather patterns, or sensor readings.   
   
Multi-layer perception will be used to predict the likelihood of disaster occurring based on historical data and current conditions.   
Damage assessment- After disaster, an MLP will analyse images or sensor data to assess the extent of damage. The MLP will also be trained to access the level of damage that was done to the infrastructure and other essential things.   
MLPs will then process social media data to extract real-time information about disaster impacts, public sentiment, and requests for help. This crucial information will then inform us about what is happening on the ground and help authorities making informed decisions.
